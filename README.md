# üê≥ Compte-Rendu TP Docker Swarm - Orchestration de Cluster

![Status](https://img.shields.io/badge/Status-Completed-success)
![Docker](https://img.shields.io/badge/Docker-27.3.1-blue)
![Nodes](https://img.shields.io/badge/Nodes-4-orange)

Ce projet documente la mise en place d'un cluster orchestr√© avec Docker Swarm. L'infrastructure est compos√©e de 4 instances Linux simulant un environnement de production distribu√©.

## üìã Guide Technique Pas √† Pas

### 1Ô∏è‚É£ Mise en place du Cluster (Exercice 1)
L'objectif est d'initialiser le mode Swarm sur le manager et de f√©d√©rer les 3 workers pour former le cluster.

<details>
<summary>üíª Voir les commandes terminal</summary>

**Sur le Node 1 (Manager) :**
* Initialisation du cluster :
    ```bash
    docker swarm init --advertise-addr 192.168.0.34
    ```
* V√©rification de l'√©tat du cluster :
    ```bash
    docker node ls
    ```
</details>

![Nodes List](./cluster_nodes.png)

---

### 2Ô∏è‚É£ R√©plication & Visualisation (Exercice 2)
Mise en place d'un outil de monitoring graphique et test de la haute disponibilit√© (self-healing).

<details>
<summary>üíª Voir les commandes terminal</summary>

**Sur le Node 1 :**
* Lancer le Visualizer en mode standalone sur le port 8080 :
    ```bash
    docker run -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer
    ```
* Cr√©er un service de 2 r√©plicas (image alpine) :
    ```bash
    docker service create --name pingpong --replicas 2 -d alpine ping -c 5 perdu.com
    ```
</details>

![PingPong Replicas](./visualizer_pingpong.png)

---

### 3Ô∏è‚É£ Load Balancing (Exercice 3)
D√©ploiement d'un service web r√©parti pour tester l'√©quilibrage de charge natif via le port 80.

<details>
<summary>üíª Voir les commandes terminal</summary>

**Sur le Node 1 :**
* D√©ploiement du service `loadb` avec 4 r√©plicas :
    ```bash
    docker service create --name loadb --replicas 4 -p 80:80 flointech/hello-name
    ```

**V√©rification :**
* L'acc√®s au port 80 retourne l'ID du conteneur. En rafra√Æchissant la page, l'ID change, prouvant la r√©partition du trafic.
</details>

![LoadBalancing Result](./test_d'√©quilibrage_de_charge.png)

---

### 4Ô∏è‚É£ Registry Priv√© & D√©ploiement Local (Exercice 4)
Configuration d'un magasin d'images interne pour s√©curiser et centraliser les d√©ploiements.

<details>
<summary>üíª Voir les commandes terminal</summary>

**Sur CHAQUE Node (1, 2, 3, 4) :**
* Configurer les `insecure-registries` dans `/etc/docker/daemon.json` :
    ```json
    { "insecure-registries": ["127.0.0.1", "192.168.0.34:5000"] }
    ```
* Recharger la configuration : `kill -HUP $(pidof dockerd)`

**Sur le Node 1 (Push et Cr√©ation) :**
* Pousser l'image vers le registry local :
    ```bash
    docker pull alpine
    docker tag alpine 192.168.0.34:5000/mon-image
    docker push 192.168.0.34:5000/mon-image
    ```
* Cr√©er le service final √† partir de l'image priv√©e :
    ```bash
    docker service create --name service-prive --replicas 4 192.168.0.34:5000/mon-image ping 8.8.8.8
    ```
</details>

![Registry Push](./registry_push.png)

---

## üñºÔ∏è R√©sultat Final
Vue d'ensemble du cluster via le **Visualizer** montrant la coexistence et la r√©partition des services sur les 4 n≈ìuds.

![Visualizer Final](./image_e45579.jpg.png)

## üèÅ Conclusion
Ce TP a valid√© les capacit√©s de Docker Swarm en termes de **haute disponibilit√©**, de **load balancing** automatique et de gestion de **registre priv√©**.
